# Copy this file to .env and fill in values

# Server
PORT=8080

# Feature toggles
USE_LLM_PLANNER=1
USE_LLM_VERIFIER=1
# Use unified delegator tool in plans (call_tool)
USE_UNIFIED_TOOL=1

# Generic LLM configuration
# Choose provider: openai | anthropic | gemini
LLM_PROVIDER=openai
# Optional model override; sensible defaults are used if omitted
# e.g., gpt-4o-mini | claude-3-5-sonnet-latest | gemini-1.5-flash
LLM_MODEL=

# Provider API keys (set the one matching LLM_PROVIDER)
#OPENAI_API_KEY=
#ANTHROPIC_API_KEY=
#GOOGLE_API_KEY=

# Size/throughput caps (tune for performance)
# Max upload size processed by file_extract (bytes)
FILE_MAX_BYTES=20000000
# Cap extracted text size from PDF/HTML and HTTP GET bodies (bytes)
PDF_MAX_TEXT_BYTES=500000
HTML_TO_TEXT_MAX_BYTES=500000
HTTP_GET_MAX_BYTES=2000000

# Chunked summarization defaults
CHUNK_CHARS=8000
CHUNK_OVERLAP=400
CHUNK_MAX_PAR=3
